# -*- coding: utf-8 -*-
"""Ramen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18SztjV8st_ldSjNKiv_Dcwc1AbV67DXr

# Import Library
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

import warnings
warnings.filterwarnings('ignore')

"""# Data Loading

Langkah ini bertujuan untuk memuat dataset yang diperlukan untuk membangun sistem rekomendasi.
"""

# Path dataset yang sudah kamu upload ke Colab
file_path = '/content/ramen-ratings.csv'

# Membaca dataset CSV menggunakan pandas
df = pd.read_csv(file_path)

# Menampilkan ukuran dataset dan 5 baris pertama sebagai gambaran awal
print("Ukuran dataset:", df.shape)
print(df.head())

"""#  Data Understanding.

Pada tahap ini awal dalam proses analisis data yang bertujuan untuk mengenal dan memahami struktur, tipe, serta kualitas data ramen yang digunakan dalam penelitian. Pada tahap ini, dilakukan pemeriksaan terhadap jumlah data, tipe variabel, serta kelengkapan data termasuk pengecekan nilai yang hilang (missing values).
"""

# Menampilkan info struktur dataset (tipe data dan non-null count)
print("Info dataset:")
print(df.info())

# Menampilkan statistik deskriptif untuk kolom numerik dan kategori
print("\nStatistik deskriptif:")
print(df.describe(include='all'))

# Cek missing value di tiap kolom
print("\nJumlah missing values per kolom:")
print(df.isnull().sum())

df = df.drop(columns=['Top Ten'])
print("Kolom 'Top Ten' sudah dihapus.")

# Ubah 'Stars' ke numeric, dengan errors='coerce' agar nilai yang tidak bisa diubah jadi NaN
df['Stars'] = pd.to_numeric(df['Stars'], errors='coerce')

# Isi missing di kolom 'Style' dengan 'Unknown'
df['Style'] = df['Style'].fillna('Unknown')

# Cek kembali jumlah missing setelah perubahan
print("Missing values setelah preprocessing:")
print(df.isnull().sum())

# Buang baris dengan nilai Stars yang kosong
df = df.dropna(subset=['Stars'])

# Cek kembali ukuran data setelah drop
print("Ukuran data setelah menghapus baris tanpa rating:", df.shape)

"""# Exploratory Data Analysis (EDA)

Melalui tahap ini, dilakukan analisis distribusi rating (Stars) untuk mengetahui sebaran preferensi pengguna terhadap produk ramen. Selain itu, dilakukan identifikasi brand-brand dengan rata-rata rating tertinggi guna memberikan gambaran merek mana yang memiliki kualitas unggul menurut data rating.karakteristik dan pola dalam dataset
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Distribusi rating (Stars)
plt.figure(figsize=(8,5))
sns.countplot(data=df, x='Stars', palette='viridis')
plt.title('Distribusi Rating Ramen (Stars)')
plt.xlabel('Rating (Stars)')
plt.ylabel('Jumlah Data')
plt.show()

# Rating rata-rata per Brand (top 10 brand dengan rating tertinggi)
avg_rating_brand = df.groupby('Brand')['Stars'].mean().sort_values(ascending=False).head(10)

plt.figure(figsize=(10,6))
sns.barplot(x=avg_rating_brand.values, y=avg_rating_brand.index, palette='magma')
plt.title('Top 10 Brand dengan Rating Ramen Tertinggi (Rata-rata)')
plt.xlabel('Rata-rata Rating (Stars)')
plt.ylabel('Brand')
plt.show()

print("Top 10 Brand dengan Rating Tertinggi:")
print(avg_rating_brand)

"""# Data Preparation

Tahap Data Preparation ini memastikan dataset dalam kondisi bersih, lengkap, dan sesuai dengan kebutuhan algoritma rekomendasi yang akan digunakan pada tahap berikutnya, baik content-based maupun collaborative filtering.
"""

# Pastikan Stars sudah numeric dan tidak ada missing
print("Jumlah missing values pada Stars:", df['Stars'].isnull().sum())

# Isi missing value kolom 'Country' jika ada
df['Country'] = df['Country'].fillna('Unknown')

# Cek kolom 'Country' sebagai proxy user
print("Jumlah data unik Country (sebagai user):", df['Country'].nunique())

# Contoh tampilkan beberapa data
print(df[['Country', 'Brand', 'Variety', 'Stars']].head())

"""# Model Development dengan Content-Based Filtering

Pada tahap Model Content-Based Filtering menggunakan TF-IDF untuk merepresentasikan teks ramen dan cosine similarity untuk mengukur kemiripan antar ramen. Fungsi rekomendasi mengembalikan 10 ramen paling mirip berdasarkan kemiripan konten, memudahkan pengguna menemukan ramen serupa tanpa data preferensi pengguna.

## TF-IDF Vectorizer
TF-IDF (Term Frequency-Inverse Document Frequency) digunakan untuk mengubah deskripsi ramen (Variety) menjadi representasi numerik berbobot berdasarkan frekuensi kata penting.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Membuat objek TF-IDF Vectorizer dengan stop words bahasa Inggris
tfidf = TfidfVectorizer(stop_words='english')

# Terapkan TF-IDF pada kolom 'Variety'
tfidf_matrix = tfidf.fit_transform(df['Variety'])

# Cek ukuran matriks TF-IDF (baris = jumlah ramen, kolom = fitur kata unik)
print("Shape TF-IDF matrix:", tfidf_matrix.shape)

"""## Cosine Similarity

Cosine similarity  menghitung tingkat kemiripan antar ramen berdasarkan representasi TF-IDF.
"""

from sklearn.metrics.pairwise import cosine_similarity

# Hitung cosine similarity antar baris TF-IDF matrix
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Cek ukuran matrix similarity
print("Shape cosine similarity matrix:", cosine_sim.shape)

"""## Buat Indeks Nama Ramen"""

print(df['Variety'].unique())

print(df['Variety'].head(10))

# Membuat indeks dari kolom 'Variety' untuk pencarian
indices = pd.Series(df.index, index=df['Variety']).drop_duplicates()

# Contoh cek indeks ramen 'Shin Black'
print("Indeks ramen 'Singapore Curry':", indices['Singapore Curry'])

def recommend_ramen_content_based(title, cosine_sim=cosine_sim, df=df):
    indices = pd.Series(df.index, index=df['Variety']).drop_duplicates()

    if title not in indices:
        return f"Ramen dengan nama '{title}' tidak ditemukan dalam data."

    idx = indices[title]

    # Ambil baris similarity untuk ramen ini, pastikan 1D array
    sim_scores_array = cosine_sim[idx]

    # Kalau sim_scores_array bentuknya 2D, flatten dulu
    if sim_scores_array.ndim > 1:
        sim_scores_array = sim_scores_array.flatten()

    # Buat list tuple (index, similarity_score)
    sim_scores = list(enumerate(sim_scores_array))

    # Sort berdasarkan similarity descending, ambil 10 teratas kecuali diri sendiri
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Hapus diri sendiri (indeks idx)
    sim_scores = [x for x in sim_scores if x[0] != idx]

    # Ambil 10 teratas
    sim_scores = sim_scores[:10]

    ramen_indices = [i[0] for i in sim_scores]

    recommended = df.iloc[ramen_indices][['Brand', 'Variety', 'Style', 'Country', 'Stars']]

    return recommended.reset_index(drop=True)

result = recommend_ramen_content_based('Singapore Curry')
print(result)

"""# Model Development dengan Collaborative Filtering

## Membuat matriks user-item

Pada tahap ini, kita mengembangkan model rekomendasi dengan pendekatan Collaborative Filtering menggunakan kolom Country sebagai proxy pengguna untuk membuat matriks user-item berdasarkan rating ramen. Kemiripan antar pengguna dihitung dengan cosine similarity, lalu rekomendasi dibuat dengan memanfaatkan preferensi pengguna serupa. Pendekatan ini memungkinkan sistem memprediksi ramen yang disukai pengguna berdasarkan pola rating kolektif dalam data.

## Membagi data menjadi training dan testing
 kita bagi data menjadi training (80%) dan testing (20%) dengan stratified sampling berdasarkan user agar distribusi rating tetap merata.
"""

train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Country_mod'])

# Membuat kolom modifikasi Country
country_counts = df['Country'].value_counts()
rare_countries = country_counts[country_counts < 2].index.tolist()
df['Country_mod'] = df['Country'].apply(lambda x: 'Others' if x in rare_countries else x)

country_counts = df['Country'].value_counts()
rare_countries = country_counts[country_counts < 2].index.tolist()
df['Country_mod'] = df['Country'].apply(lambda x: 'Others' if x in rare_countries else x)

train_data, test_data = train_test_split(df, test_size=0.2, random_state=42, stratify=df['Country_mod'])
print("Data training shape:", train_data.shape)
print("Data testing shape:", test_data.shape)

# Membuat matriks user-item dari data training
train_matrix = train_data.pivot_table(index='Country', columns='Variety', values='Stars')

print("Shape matriks training user-item:", train_matrix.shape)
train_matrix.head()

"""## Hitung similarity antar user
Untuk membuat rekomendasi berbasis user (User-Based Collaborative Filtering), kita hitung similarity antar user menggunakan cosine similarity dengan mengisi nilai NaN menjadi 0.
"""

from sklearn.metrics.pairwise import pairwise_distances
import numpy as np

# Isi NaN dengan 0 untuk hitung similarity
train_matrix_filled = train_matrix.fillna(0)

# Hitung cosine similarity antar user (Country)
user_similarity = 1 - pairwise_distances(train_matrix_filled, metric='cosine')

print("Shape matriks similarity user:", user_similarity.shape)

"""## Fungsi Rekomendasi Collaborative Filtering"""

def recommend_ramen_collaborative(user_id, user_similarity=user_similarity, train_matrix=train_matrix):
    if user_id not in train_matrix.index:
        return f"User '{user_id}' tidak ditemukan dalam data training."

    # Ambil indeks user
    user_idx = train_matrix.index.get_loc(user_id)

    # Ambil skor similarity user terhadap user lain
    sim_scores = list(enumerate(user_similarity[user_idx]))

    # Urutkan berdasarkan similarity tertinggi (kecuali diri sendiri)
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = [x for x in sim_scores if x[0] != user_idx]

    # Ambil 10 user paling mirip
    top_users = [train_matrix.index[i[0]] for i in sim_scores[:10]]

    # Ambil ramen yang user belum rating
    user_rated = train_matrix.loc[user_id].dropna().index.tolist()

    # Rata-rata rating ramen dari user mirip yang belum dicoba user_id
    candidate_ratings = train_matrix.loc[top_users].mean(axis=0).dropna()
    candidate_ratings = candidate_ratings.drop(user_rated, errors='ignore')

    # Urutkan dan ambil 10 rekomendasi teratas
    recommendations = candidate_ratings.sort_values(ascending=False).head(10)

    result = pd.DataFrame({
        'Ramen': recommendations.index,
        'Predicted Rating': recommendations.values
    })

    return result.reset_index(drop=True)

sample_user = train_matrix.index[0]  # ambil user pertama sebagai contoh
print(f"Rekomendasi ramen untuk user '{sample_user}':")
print(recommend_ramen_collaborative(sample_user))